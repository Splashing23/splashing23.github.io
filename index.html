<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Dev Gupta</title>

    <meta name="author" content="Dev Gupta">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/dev_gupta_circle.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Dev Gupta
                </p>
                <p>I am an undergraduate researcher working at the <a href="https://mvrl.cse.wustl.edu/ target="_blank"">Multimodal Vision Research Lab</a> at <a href="https://wustl.edu/ target="_blank"">Washington University in St. Louis</a>.
                </p>
                <p>
                  I received my B.S. in Computer Science & Mathematics with a second major in Financial Engineering at WashU.
                </p>
                <p style="text-align:center">
                  <a href="mailto:dev.g@wustl.edu" target="_blank">Email</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/gupta-dev/" target="_blank">LinkedIn</a> &nbsp;/&nbsp;
                  <!-- <a href="https://scholar.google.com/citations?user=a-RC9VkAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/Splashing23" target="_blank">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://huggingface.co/Splash23" target="_blank">HuggingFace</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/dev_gupta_circle.png" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>

          <h2 style="padding-left:20px">Summary</h2>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                <p>
                  I've recently graduated with expertise in developing state-of-the-art machine learning models and optimizing AI inferences for scalability and performance. I've successfully engineered a multimodal model and retrieval system utilizing dense vision embeddings and developed a cross-vision pose estimation model that conditions on 3D reconstructions. I am eager to apply technical skills and innovative solutions in advanced AI projects.
                </p>
              </td>
            </tr>
          </tbody></table>

          <h2 style="padding-left:20px">Featured In</h2>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                <p>
                  Quoted in WashU's The Source - <a href="https://source.washu.edu/?p=711521&preview=1&_ppp=24e7d1a6fd" target="_blank">Read Article</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <h2 style="padding-left:20px">Supplementary Material</h2>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                <ul>
                  <li><a href="presentation.pdf" target="_blank">DI2 Project Presentation</a></li>
                  <li><a href="https://di2accelerator.wustl.edu/digital-transformation-corps/vision-language-models-for-urban-health-assessment/" target="_blank">DI2 Project Report</a></li>
                </ul>
              </td>
            </tr>
          </tbody></table>

<!--           <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2 style="padding-left:20px">Publications</h2>
            <tr>
              <script
              	type="module"
              	src="https://gradio.s3-us-west-2.amazonaws.com/4.36.1/gradio.js"
              ></script>
              
              <gradio-app src="https://splash23-screwimageclassifier.hf.space"></gradio-app>
            </tr>
          </tbody></table> -->


          <!--

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2 style="padding-left:20px">Publications</h2>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/QuARI.png" alt="QuARI_NIPS_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">QuARI: Query Adaptive Retrieval Improvement</span><br><strong>Eric Xing</strong>,
                <a href="https://cs.slu.edu/~stylianou/">Abby Stylianou</a>,
                <a href="https://www2.seas.gwu.edu/~pless/">Robert Pless</a>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
                <em>arXiv</em>, 2025<br>
                <a href="https://arXiv.org/abs/2505.21647">arXiv</a> /
                <a href="https://github.com/mvrl/QuARI">code</a>
                <p>Hypernetwork-based framework for dynamic database feature adapation, for retrieval and large-scale reranking.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/rcme_iccv.png" alt="RCME_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">Global and Local Entailment Learning for Natural World Imagery</span><br><a href="https://vishu26.github.io/">Srikumar Sastry</a>,
                <a href="https://www.linkedin.com/in/aayush-dhakal">Aayush Dhakal</a>,
                <strong>Eric Xing</strong>,
                <a href="https://subash-khanal.github.io/">Subash Khanal</a>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
                <em>International Conference on Computer Vision (ICCV)</em>, 2025<br>
                <a href="https://vishu26.github.io/RCME/index.html">website</a> /
                <a href="https://arXiv.org/abs/2506.21476">arXiv</a>
                <p>We introduce a framework that explicitly enforces the modeling of transitivity-enforced entailment for the partial order of concepts within vision-language models.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/GenStereo.png" alt="GenStereo_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">GenStereo: Towards Open-World Generation of Stereo Images and Unsupervised Matching</span><br><a href="https://qjizhi.github.io/">Feng Qiao</a>,
                <a href="https://steven-xiong.github.io/">Zhexiao Xiong</a>,
                <strong>Eric Xing</strong>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
                <em>International Conference on Computer Vision (ICCV)</em>, 2025<br>
                <a href="https://qjizhi.github.io/genstereo">website</a> /
                <a href="https://arXiv.org/abs/2503.12720">arXiv</a> /
                <a href="https://github.com/Qjizhi/GenStereo">code</a>
                <p>GenStereo uses a diffusion-based approach with disparity-aware conditioning for strong performance in stereo image generation and unsupervised stereo matching.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/contextcir.png" alt="ConText-CIR_CVPR_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">ConText-CIR: Learning from Concept in Text for Composed Image Retrieval</span><br><strong>Eric Xing</strong>,
                <a href="https://www.linkedin.com/in/pranavi-kolouju-a77582247">Pranavi Kolouju</a>,
                <a href="https://www2.seas.gwu.edu/~pless/">Robert Pless</a>,
                <a href="https://cs.slu.edu/~stylianou/">Abby Stylianou</a>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025<br>
                <a href="https://arXiv.org/abs/2505.20764">arXiv</a> /
                <a href="https://github.com/mvrl/ConText-CIR">code</a> /
                <a href="https://ericx003.github.io/proj/context_cir/">website</a>
                <p>State-of-the-art composed image retrieval by bootstrapping learning from concept representations.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/range.png" alt="RANGE_CVPR_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">RANGE: Retrieval Augmented Neural Fields for Multi-Resolution Geo-Embeddings</span><br><a href="https://www.linkedin.com/in/aayush-dhakal">Aayush Dhakal</a>,
                <a href="https://vishu26.github.io/">Srikumar Sastry</a>,
                <a href="https://subash-khanal.github.io/">Subash Khanal</a>,
                <a href="https://adealgis.wixsite.com/adeel-ahmad-geog">Adeel Ahmad</a>,
                <strong>Eric Xing</strong>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025<br>
                <a href="https://arXiv.org/abs/2502.19781">arXiv</a> /
                <a href="https://github.com/mvrl/RANGE">code</a>
                <p>We develop a retrieval-augmented strategy for geospatial representation learning, significantly improving performance on downstream tasks.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/good4cir.png" alt="good4CIR_CVPRW_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">good4cir: Generating Detailed Synthetic Captions for Composed Image Retrieval</span><br><a href="https://www.linkedin.com/in/pranavi-kolouju-a77582247">Pranavi Kolouju</a>,
                <strong>Eric Xing</strong>,
                <a href="https://www2.seas.gwu.edu/~pless/">Robert Pless</a>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a>,
                <a href="https://cs.slu.edu/~stylianou/">Abby Stylianou</a><br>
                <em>2nd Workshop on Harnessing Generative Models for Synthetic Visual Datasets at CVPR</em>, 2025<br>
                <a href="https://arXiv.org/abs/2503.17871">arXiv</a> /
                <a href="https://github.com/SLUVisLab/good4cir">code</a>
                <p>Dataset synthesis pipeline to for training of powerful composed image retrieval models.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/PSM_Birds.png" alt="PSM_ACMMM_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="data/PSM_ACMMM.pdf">
                  <span class="papertitle">PSM: Learning Probabilistic Embeddings for Multi-scale Zero-Shot Soundscape Mapping</span>
                </a><br><a href="https://subash-khanal.github.io/">Subash Khanal</a>,
                <strong>Eric Xing</strong>,
                <a href="https://vishu26.github.io/">Srikumar Sastry</a>,
                <a href="https://www.linkedin.com/in/aayush-dhakal">Aayush Dhakal</a>,
                <a href="https://steven-xiong.github.io/">Zhexiao Xiong</a>,
                <a href="https://adealgis.wixsite.com/adeel-ahmad-geog">Adeel Ahmad</a>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
                <em>ACM Multimedia</em>, 2024<br>
                <a href="data/PSM_ACMMM.pdf">paper</a> /
                <a href="https://arXiv.org/abs/2408.07050">arXiv</a> /
                <a href="https://github.com/mvrl/PSM">code</a> /
                <a href="data/PSM_ACMMM.bib">bibtex</a>
                <p>We develop a probabilistic, multi-scale, and metadata-aware embedding space that connects audio, text, and overhead imagery.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/AAAI_ALISON.png" alt="AAAI_ALISON_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="data/ALISON_AAAI.pdf">
                  <span class="papertitle">ALISON: Fast and Effective Stylometric Authorship Obfuscation</span>
                </a><br><strong>Eric Xing</strong>,
                <a href="https://ist.psu.edu/directory/szv4">Saranya Venkatraman</a>,
                <a href="https://engineering.olemiss.edu/people-thai-le/">Thai Le</a>,
                <a href="https://ist.psu.edu/directory/dul13">Dongwon Lee</a><br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024<br>
                <a href="data/ALISON_AAAI.pdf">paper</a> /
                <a href="https://arXiv.org/abs/2402.00835">arXiv</a> /
                <a href="https://github.com/EricX003/ALISON">code</a> /
                <a href="data/ALISON_AAAI.bib">bibtex</a>
                <p>An authorship obfuscation method that demonstrates a ~10x speedup over previous methods while outperforming them in terms of attack success, semantic preservation, and fluency.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/ICPR_Uncertainty.png" alt="ICPR_Uncertainty_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="data/CNN_Feature_Space_Uncertainty_ICPR2022_.pdf">
                  <span class="papertitle">Neural Network Decision-Making Criteria Consistency Analysis via Inputs Sensitivity</span>
                </a><br><strong>Eric Xing</strong>,
                <a href="https://ieeexplore.ieee.org/author/37086329288">Liangliang Liu</a>,
                <a href="https://xtrigold.github.io/">Xin Xing</a>,
                <a href="https://www.linkedin.com/in/yunni-qu">Yunni Qu</a>,
                <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a>,
                <a href="http://www.gb-liang.com/">Gongbo Liang</a><br>
                <em>International Conference on Pattern Recognition (ICPR)</em>, 2022<br>
                <a href="data/CNN_Feature_Space_Uncertainty_ICPR2022_.pdf">paper</a> /
                <a href="data/FeatureUncertainty_ICPR.bib">bibtex</a>
                <p>Quantification and analysis of neural network decision-making criteria inconsistency and three algorithms to mitigate this inconsistency with minimal performance sacrifice.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/EMBC_Beware.png" alt="EMBC_Beware_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="data/Image_Generation_Feature_Uncertainty_EMBC2022_.pdf">
                  <span class="papertitle">Beware the Black-Box of Medical Image Generation: an Uncertainty Analysis by the Learned Feature Space</span>
                </a><br><a href="https://www.linkedin.com/in/yunni-qu">Yunni Qu</a>,
                <a href="https://www.linkedin.com/in/david-yan-695767165/">David Yan</a>,
                <strong>Eric Xing</strong>,
                <a href="https://scholar.google.com/citations?user=WtPtkd4AAAAJ&hl=en">Fengbo Zheng</a>,
                <a href="https://medicine.uky.edu/departments/radiology/users/jnzh222/">Jie Zhang</a>,
                <a href="https://ieeexplore.ieee.org/author/37086329288">Liangliang Liu</a>,
                <a href="http://www.gb-liang.com/">Gongbo Liang</a><br>
                <em>International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</em>, 2022<br>
                <a href="data/Image_Generation_Feature_Uncertainty_EMBC2022_.pdf">paper</a> /
                <a href="data/Beware_EMBC.bib">bibtex</a>
                <p>Quantitative and clustering-based analyses of learned features spaces of U-Net architechtures for medical image generation.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/SIGCSE_Toolkit.png" alt="SIGCSE_Toolkit_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="data/Toolkit_SIGCSE.pdf">
                  <span class="papertitle">A Toolkit for Assessments in Introductory Programming Courses</span>
                </a><br><strong>Eric Xing</strong>,
                <a href="https://www.wku.edu/seas/staff/guangming_xing">Guangming Xing</a><br>
                <em>ACM Technical Symposium on Computer Science Education (SIGCSE)</em>, 2022<br>
                <a href="data/Toolkit_SIGCSE.pdf">paper</a> /
                <a href="data/Toolkit_SIGCSE.bib">bibtex</a>
                <p>A versatile online exam toolkit with plagarism and cheating detection as part of the vLab learning management system.</p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="tn/images/Motorcycle_ICTD.jpeg" alt="Motorcycle_ICTD_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="data/Motorcycle_ASCEICTD2022.pdf">
                  <span class="papertitle">Motorcycle Safety Investigation in Kentucky Using Machine and Deep Learning Techniques</span>
                </a><br><strong>Eric Xing</strong>,
                <a href="https://www.wku.edu/seas/staff/kirolos_haleem">Kirolos Haleem</a><br>
                <em>International Conference on Transportation and Development</em>, 2022<br>
                <a href="data/Motorcycle_ASCEICTD2022.pdf">paper</a> /
                <a href="data/Motorcycle_ICTD.bib">bibtex</a>
                <p>Interpretability over a new state-of-the-art pipeline for motorcycle crash severity predicition for the analysis of factors contributing to severe motorcycle crashes.</p>
              </td>
            </tr>
          </tbody></table>

          -->
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                      <td style="padding:0px">
                        <br>
                        <p style="text-align:center;font-size:small;">
                          Thank you to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> for the site template.
                        </p>
                      </td>
                    </tr>
          </tbody></table>
        </td>
      </tr>
    </tbody></table>

  </body>
</html>
