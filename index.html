<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Eric Xing</title>

    <meta name="author" content="Eric Xing">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Eric Xing
                </p>
                <p>I am a PhD student in the <a href="https://mvrl.cse.wustl.edu/">Multimodal Vision Research Lab</a> at <a href="https://wustl.edu/">Washington University in St. Louis</a>, where I work on multimodal learning and retrieval. I am advised by <a href="https://jacobsn.github.io/">Nathan Jacobs</a>.
                </p>
                <p>
                  I received my B.S. in Computer Science with a minor in mathematics from <a href="https://www.wku.edu/">Western Kentucky University</a>. I also worked with <a href="https://pike.psu.edu/dongwon/">Dongwon Lee</a> as part of an <a href="https://reu.ist.psu.edu/">REU</a> at <a href="https://www.psu.edu/">Penn State University</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:e.xing@wustl.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/research/cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ericx003/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=a-RC9VkAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/EricX003">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/portrait_circle.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="tn/images/portrait_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research broadly lies in vision-language models and multimodal learning. I am currently working on various flavors of multimodal retrieval. 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <h2>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Publications</h2>
          
            

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/QuARI.png" alt="QuARI_NIPS_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <span class="papertitle">QuARI: Query Adaptive Retrieval Improvement</span><br><strong>Eric Xing</strong>,
        <a href="https://cs.slu.edu/~stylianou/">Abby Stylianou</a>,
        <a href="https://www2.seas.gwu.edu/~pless/">Robert Pless</a>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
        <em>arXiv</em>, 2025<br>
        <a href="https://arXiv.org/abs/2505.21647">arXiv</a> /
        <a href="https://github.com/mvrl/QuARI">code</a>
        <p>Hypernetwork-based framework for dynamic database feature adapation, for retrieval and large-scale reranking.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/rcme_iccv.png" alt="RCME_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <span class="papertitle">Global and Local Entailment Learning for Natural World Imagery</span><br><a href="https://vishu26.github.io/">Srikumar Sastry</a>,
        <a href="https://www.linkedin.com/in/aayush-dhakal">Aayush Dhakal</a>,
        <strong>Eric Xing</strong>,
        <a href="https://subash-khanal.github.io/">Subash Khanal</a>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
        <em>International Conference on Computer Vision (ICCV)</em>, 2025<br>
        <a href="https://vishu26.github.io/RCME/index.html">website</a> /
        <a href="https://arXiv.org/abs/2506.21476">arXiv</a>
        <p>We introduce a framework that explicitly enforces the modeling of transitivity-enforced entailment for the partial order of concepts within vision-language models.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/GenStereo.png" alt="GenStereo_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <span class="papertitle">GenStereo: Towards Open-World Generation of Stereo Images and Unsupervised Matching</span><br><a href="https://qjizhi.github.io/">Feng Qiao</a>,
        <a href="https://steven-xiong.github.io/">Zhexiao Xiong</a>,
        <strong>Eric Xing</strong>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
        <em>International Conference on Computer Vision (ICCV)</em>, 2025<br>
        <a href="https://qjizhi.github.io/genstereo">website</a> /
        <a href="https://arXiv.org/abs/2503.12720">arXiv</a> /
        <a href="https://github.com/Qjizhi/GenStereo">code</a>
        <p>GenStereo uses a diffusion-based approach with disparity-aware conditioning for strong performance in stereo image generation and unsupervised stereo matching.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/contextcir.png" alt="ConText-CIR_CVPR_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <span class="papertitle">ConText-CIR: Learning from Concept in Text for Composed Image Retrieval</span><br><strong>Eric Xing</strong>,
        <a href="https://www.linkedin.com/in/pranavi-kolouju-a77582247">Pranavi Kolouju</a>,
        <a href="https://www2.seas.gwu.edu/~pless/">Robert Pless</a>,
        <a href="https://cs.slu.edu/~stylianou/">Abby Stylianou</a>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025<br>
        <a href="https://arXiv.org/abs/2505.20764">arXiv</a> /
        <a href="https://github.com/mvrl/ConText-CIR">code</a> /
        <a href="https://ericx003.github.io/proj/context_cir/">website</a>
        <p>State-of-the-art composed image retrieval by bootstrapping learning from concept representations.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/range.png" alt="RANGE_CVPR_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <span class="papertitle">RANGE: Retrieval Augmented Neural Fields for Multi-Resolution Geo-Embeddings</span><br><a href="https://www.linkedin.com/in/aayush-dhakal">Aayush Dhakal</a>,
        <a href="https://vishu26.github.io/">Srikumar Sastry</a>,
        <a href="https://subash-khanal.github.io/">Subash Khanal</a>,
        <a href="https://adealgis.wixsite.com/adeel-ahmad-geog">Adeel Ahmad</a>,
        <strong>Eric Xing</strong>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025<br>
        <a href="https://arXiv.org/abs/2502.19781">arXiv</a> /
        <a href="https://github.com/mvrl/RANGE">code</a>
        <p>We develop a retrieval-augmented strategy for geospatial representation learning, significantly improving performance on downstream tasks.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/good4cir.png" alt="good4CIR_CVPRW_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <span class="papertitle">good4cir: Generating Detailed Synthetic Captions for Composed Image Retrieval</span><br><a href="https://www.linkedin.com/in/pranavi-kolouju-a77582247">Pranavi Kolouju</a>,
        <strong>Eric Xing</strong>,
        <a href="https://www2.seas.gwu.edu/~pless/">Robert Pless</a>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a>,
        <a href="https://cs.slu.edu/~stylianou/">Abby Stylianou</a><br>
        <em>2nd Workshop on Harnessing Generative Models for Synthetic Visual Datasets at CVPR</em>, 2025<br>
        <a href="https://arXiv.org/abs/2503.17871">arXiv</a> /
        <a href="https://github.com/SLUVisLab/good4cir">code</a>
        <p>Dataset synthesis pipeline to for training of powerful composed image retrieval models.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/PSM_Birds.png" alt="PSM_ACMMM_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="data/PSM_ACMMM.pdf">
          <span class="papertitle">PSM: Learning Probabilistic Embeddings for Multi-scale Zero-Shot Soundscape Mapping</span>
        </a><br><a href="https://subash-khanal.github.io/">Subash Khanal</a>,
        <strong>Eric Xing</strong>,
        <a href="https://vishu26.github.io/">Srikumar Sastry</a>,
        <a href="https://www.linkedin.com/in/aayush-dhakal">Aayush Dhakal</a>,
        <a href="https://steven-xiong.github.io/">Zhexiao Xiong</a>,
        <a href="https://adealgis.wixsite.com/adeel-ahmad-geog">Adeel Ahmad</a>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a><br>
        <em>ACM Multimedia</em>, 2024<br>
        <a href="data/PSM_ACMMM.pdf">paper</a> /
        <a href="https://arXiv.org/abs/2408.07050">arXiv</a> /
        <a href="https://github.com/mvrl/PSM">code</a> /
        <a href="data/PSM_ACMMM.bib">bibtex</a>
        <p>We develop a probabilistic, multi-scale, and metadata-aware embedding space that connects audio, text, and overhead imagery.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/AAAI_ALISON.png" alt="AAAI_ALISON_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="data/ALISON_AAAI.pdf">
          <span class="papertitle">ALISON: Fast and Effective Stylometric Authorship Obfuscation</span>
        </a><br><strong>Eric Xing</strong>,
        <a href="https://ist.psu.edu/directory/szv4">Saranya Venkatraman</a>,
        <a href="https://engineering.olemiss.edu/people-thai-le/">Thai Le</a>,
        <a href="https://ist.psu.edu/directory/dul13">Dongwon Lee</a><br>
        <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024<br>
        <a href="data/ALISON_AAAI.pdf">paper</a> /
        <a href="https://arXiv.org/abs/2402.00835">arXiv</a> /
        <a href="https://github.com/EricX003/ALISON">code</a> /
        <a href="data/ALISON_AAAI.bib">bibtex</a>
        <p>An authorship obfuscation method that demonstrates a ~10x speedup over previous methods while outperforming them in terms of attack success, semantic preservation, and fluency.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/ICPR_Uncertainty.png" alt="ICPR_Uncertainty_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="data/CNN_Feature_Space_Uncertainty_ICPR2022_.pdf">
          <span class="papertitle">Neural Network Decision-Making Criteria Consistency Analysis via Inputs Sensitivity</span>
        </a><br><strong>Eric Xing</strong>,
        <a href="https://ieeexplore.ieee.org/author/37086329288">Liangliang Liu</a>,
        <a href="https://xtrigold.github.io/">Xin Xing</a>,
        <a href="https://www.linkedin.com/in/yunni-qu">Yunni Qu</a>,
        <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html">Nathan Jacobs</a>,
        <a href="http://www.gb-liang.com/">Gongbo Liang</a><br>
        <em>International Conference on Pattern Recognition (ICPR)</em>, 2022<br>
        <a href="data/CNN_Feature_Space_Uncertainty_ICPR2022_.pdf">paper</a> /
        <a href="data/FeatureUncertainty_ICPR.bib">bibtex</a>
        <p>Quantification and analysis of neural network decision-making criteria inconsistency and three algorithms to mitigate this inconsistency with minimal performance sacrifice.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/EMBC_Beware.png" alt="EMBC_Beware_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="data/Image_Generation_Feature_Uncertainty_EMBC2022_.pdf">
          <span class="papertitle">Beware the Black-Box of Medical Image Generation: an Uncertainty Analysis by the Learned Feature Space</span>
        </a><br><a href="https://www.linkedin.com/in/yunni-qu">Yunni Qu</a>,
        <a href="https://www.linkedin.com/in/david-yan-695767165/">David Yan</a>,
        <strong>Eric Xing</strong>,
        <a href="https://scholar.google.com/citations?user=WtPtkd4AAAAJ&hl=en">Fengbo Zheng</a>,
        <a href="https://medicine.uky.edu/departments/radiology/users/jnzh222/">Jie Zhang</a>,
        <a href="https://ieeexplore.ieee.org/author/37086329288">Liangliang Liu</a>,
        <a href="http://www.gb-liang.com/">Gongbo Liang</a><br>
        <em>International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</em>, 2022<br>
        <a href="data/Image_Generation_Feature_Uncertainty_EMBC2022_.pdf">paper</a> /
        <a href="data/Beware_EMBC.bib">bibtex</a>
        <p>Quantitative and clustering-based analyses of learned features spaces of U-Net architechtures for medical image generation.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/SIGCSE_Toolkit.png" alt="SIGCSE_Toolkit_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="data/Toolkit_SIGCSE.pdf">
          <span class="papertitle">A Toolkit for Assessments in Introductory Programming Courses</span>
        </a><br><strong>Eric Xing</strong>,
        <a href="https://www.wku.edu/seas/staff/guangming_xing">Guangming Xing</a><br>
        <em>ACM Technical Symposium on Computer Science Education (SIGCSE)</em>, 2022<br>
        <a href="data/Toolkit_SIGCSE.pdf">paper</a> /
        <a href="data/Toolkit_SIGCSE.bib">bibtex</a>
        <p>A versatile online exam toolkit with plagarism and cheating detection as part of the vLab learning management system.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="tn/images/Motorcycle_ICTD.jpeg" alt="Motorcycle_ICTD_png" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="data/Motorcycle_ASCEICTD2022.pdf">
          <span class="papertitle">Motorcycle Safety Investigation in Kentucky Using Machine and Deep Learning Techniques</span>
        </a><br><strong>Eric Xing</strong>,
        <a href="https://www.wku.edu/seas/staff/kirolos_haleem">Kirolos Haleem</a><br>
        <em>International Conference on Transportation and Development</em>, 2022<br>
        <a href="data/Motorcycle_ASCEICTD2022.pdf">paper</a> /
        <a href="data/Motorcycle_ICTD.bib">bibtex</a>
        <p>Interpretability over a new state-of-the-art pipeline for motorcycle crash severity predicition for the analysis of factors contributing to severe motorcycle crashes.</p>
      </td>
    </tr>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Thank you to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> for the site template.
              </p>
            </td>
          </tr>
    </tbody>
  </table>

</body>
</html>
